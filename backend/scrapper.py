import asyncio
import logging
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from database import SessionLocal
from models import SourceChannel, Post, PostStatus
import crud
from schemas import PostCreate
from telegram_scraper_service import telegram_scraper
from telegram_service import telegram_service

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ChannelScrapper:
    def __init__(self):
        self.running = False
        self.tasks = set()
        self.scraper = telegram_scraper
        self.db = SessionLocal()
        self.monitored_channels = set()  # Track currently monitored channels
        self.continuous_task = None  # Track the main monitoring task
    
    async def start(self):
        """Start the channel scrapping worker with database control."""
        logger.info("Starting channel scrapper worker...")
        
        # Set running flag to True - CRITICAL!
        self.running = True
        
        # Mark scrapper as running in database
        crud.update_scrapper_status(self.db, is_running=True)
        
        # Initialize the scraper
        if not await self.scraper.initialize():
            logger.error("Failed to initialize Telegram scraper")
            crud.update_scrapper_status(self.db, is_running=False)
            return
        
        # Enable media downloading
        self.scraper.media_enabled = True
        logger.info("‚úÖ Media downloading enabled for scraper")
        
        # Start database status checker
        status_task = asyncio.create_task(self.check_database_status())
        self.tasks.add(status_task)
        
        # Start main monitoring loop
        logger.info("üîß DEBUG: –°–æ–∑–¥–∞—é monitor_task")
        monitor_task = asyncio.create_task(self.monitor_channels())
        self.tasks.add(monitor_task)
        logger.info(f"üîß DEBUG: monitor_task —Å–æ–∑–¥–∞–Ω–∞: {monitor_task}")
        
        # Start heartbeat task
        heartbeat_task = asyncio.create_task(self.send_heartbeat())
        self.tasks.add(heartbeat_task)
        
        # Start channel reload task
        reload_task = asyncio.create_task(self.reload_channels_periodically())
        self.tasks.add(reload_task)
        
        try:
            await asyncio.gather(*self.tasks)
        except Exception as e:
            logger.error(f"Scrapper error: {str(e)}")
        finally:
            self.running = False
            crud.update_scrapper_status(self.db, is_running=False)
            self.db.close()
    
    async def stop(self):
        """Stop the channel scrapping worker."""
        logger.info("Stopping channel scrapper worker...")
        self.running = False
        
        # Mark scrapper as stopped in database
        crud.update_scrapper_status(self.db, is_running=False)
        
        await self.scraper.stop_monitoring()
        
        for task in self.tasks:
            task.cancel()
        
        await asyncio.gather(*self.tasks, return_exceptions=True)
        self.db.close()
    
    async def check_database_status(self):
        """Check database for should_run flag and stop if needed."""
        while True:
            try:
                scrapper_status = crud.get_scrapper_status(self.db)
                if scrapper_status and not scrapper_status.should_run:
                    logger.info("Received stop signal from database")
                    self.running = False
                    break
                
                await asyncio.sleep(5)  # Check every 5 seconds
            except Exception as e:
                logger.error(f"Error checking database status: {str(e)}")
                await asyncio.sleep(10)
    
    async def send_heartbeat(self):
        """Send periodic heartbeat to database."""
        while self.running:
            try:
                crud.update_scrapper_status(self.db, heartbeat=True)
                await asyncio.sleep(30)  # Send heartbeat every 30 seconds
            except Exception as e:
                logger.error(f"Error sending heartbeat: {str(e)}")
                await asyncio.sleep(30)
    
    async def reload_channels_periodically(self):
        """Periodically reload channels from database and restart monitoring if needed."""
        logger.info("üîÑ –ó–∞–ø—É—â–µ–Ω–∞ –∑–∞–¥–∞—á–∞ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–π –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞–Ω–∞–ª–æ–≤")
        
        # Wait for initial monitoring to start and monitored_channels to be populated
        while self.running and not self.monitored_channels:
            logger.info("‚è≥ –û–∂–∏–¥–∞—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–ø–∏—Å–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–º—ã—Ö –∫–∞–Ω–∞–ª–æ–≤...")
            await asyncio.sleep(5)
        
        logger.info(f"‚úÖ –ù–∞—á–∏–Ω–∞—é –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞–Ω–∞–ª–æ–≤. –¢–µ–∫—É—â–∏–π —Å–ø–∏—Å–æ–∫: {self.monitored_channels}")
        
        while self.running:
            try:
                # Check for new channels every 30 seconds
                await asyncio.sleep(30)
                
                logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è—é –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å–ø–∏—Å–∫–µ –∫–∞–Ω–∞–ª–æ–≤...")
                
                db = SessionLocal()
                try:
                    # Get current active channels from database
                    current_channels = crud.get_source_channels(db, active_only=True)
                    current_channel_ids = {channel.channel_id for channel in current_channels}
                    
                    logger.info(f"üìä –¢–µ–∫—É—â–∏–µ –∫–∞–Ω–∞–ª—ã –≤ –ë–î: {current_channel_ids}")
                    logger.info(f"üìä –ú–æ–Ω–∏—Ç–æ—Ä–∏–º—ã–µ –∫–∞–Ω–∞–ª—ã: {self.monitored_channels}")
                    
                    # Check if channel list has changed
                    if current_channel_ids != self.monitored_channels:
                        logger.info(f"üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å–ø–∏—Å–∫–µ –∫–∞–Ω–∞–ª–æ–≤!")
                        logger.info(f"üìä –°—Ç–∞—Ä—ã–π —Å–ø–∏—Å–æ–∫: {self.monitored_channels}")
                        logger.info(f"üìä –ù–æ–≤—ã–π —Å–ø–∏—Å–æ–∫: {current_channel_ids}")
                        
                        # Update monitored channels
                        self.monitored_channels = current_channel_ids
                        
                        # Restart monitoring with new channel list
                        await self.restart_monitoring(current_channels)
                        
                        logger.info(f"‚úÖ –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–µ—Ä–µ–∑–∞–ø—É—â–µ–Ω —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º —Å–ø–∏—Å–∫–æ–º –∫–∞–Ω–∞–ª–æ–≤")
                    else:
                        logger.info(f"üìã –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è ({len(current_channel_ids)} –∫–∞–Ω–∞–ª–æ–≤)")
                        
                finally:
                    db.close()
                    
            except Exception as e:
                logger.error(f"Error reloading channels: {str(e)}")
                await asyncio.sleep(30)
    
    async def restart_monitoring(self, channels):
        """Restart monitoring with new channel list."""
        try:
            # Cancel existing continuous monitoring task if it exists
            if self.continuous_task and not self.continuous_task.done():
                logger.info(f"üõë –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é —Ç–µ–∫—É—â–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
                self.continuous_task.cancel()
                try:
                    await self.continuous_task
                except asyncio.CancelledError:
                    pass
                
                # Remove from tasks set
                self.tasks.discard(self.continuous_task)
            
            # Start new monitoring if there are channels
            if channels:
                channel_identifiers = [channel.channel_id for channel in channels]
                
                logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞—é –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –¥–ª—è {len(channel_identifiers)} –∫–∞–Ω–∞–ª–æ–≤")
                logger.info(f"üìã –ö–∞–Ω–∞–ª—ã: {[ch.channel_name for ch in channels]}")
                
                # Start new continuous monitoring
                self.continuous_task = asyncio.create_task(
                    self.scraper.start_monitoring(
                        channel_identifiers, 
                        callback=self.handle_new_message
                    )
                )
                self.tasks.add(self.continuous_task)
                
                logger.info(f"‚úÖ –ù–æ–≤—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞–ø—É—â–µ–Ω")
            else:
                logger.info(f"üì≠ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
                self.continuous_task = None
                
        except Exception as e:
            logger.error(f"Error restarting monitoring: {str(e)}")
    
    async def monitor_channels(self):
        """Main monitoring loop using TelegramChannelScraper"""
        logger.info("üöÄ –ó–∞–ø—É—â–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∫–∞–Ω–∞–ª–æ–≤")
        logger.info(f"üîß DEBUG: monitor_channels –≤—ã–∑–≤–∞–Ω, self.running = {self.running}")
        
        try:
            db = SessionLocal()
            
            # Get active source channels
            channels = crud.get_source_channels(db, active_only=True)
            
            if not channels:
                logger.info("üì≠ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞")
                self.monitored_channels = set()
                return
            
            # Extract channel identifiers and update monitored channels
            channel_identifiers = [channel.channel_id for channel in channels]
            self.monitored_channels = set(channel_identifiers)
            
            logger.info(f"üì° –ù–∞—á–∏–Ω–∞—é –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ {len(channel_identifiers)} –∫–∞–Ω–∞–ª–æ–≤")
            logger.info(f"üìã –°–ø–∏—Å–æ–∫ –∫–∞–Ω–∞–ª–æ–≤: {[ch.channel_name for ch in channels]}")
            logger.info(f"üìÖ –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")
            
            # Start continuous monitoring with callback (non-blocking)
            self.continuous_task = asyncio.create_task(
                self.scraper.start_monitoring(
                    channel_identifiers, 
                    callback=self.handle_new_message
                )
            )
            self.tasks.add(self.continuous_task)
            
            # Always start periodic fallback monitoring as additional backup
            logger.info("üîÑ –ó–∞–ø—É—Å–∫–∞—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –∫–∞–Ω–∞–ª–æ–≤...")
            fallback_task = asyncio.create_task(self.fallback_monitoring())
            self.tasks.add(fallback_task)
            logger.info(f"‚úÖ Fallback task —Å–æ–∑–¥–∞–Ω–∞: {fallback_task}")
            logger.info(f"üìä –í—Å–µ–≥–æ –∞–∫—Ç–∏–≤–Ω—ã—Ö –∑–∞–¥–∞—á: {len(self.tasks)}")
            
        except Exception as e:
            logger.error(f"üí• –û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–µ: {str(e)}")
            logger.info("üîÑ –û—Å–Ω–æ–≤–Ω–æ–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, fallback –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å...")
    
    async def handle_new_message(self, message_data: dict, channel_name: str):
        """Handle new message from TelegramChannelScraper"""
        try:
            logger.info(f"üéØ SCRAPPER CALLBACK TRIGGERED! Processing message {message_data['message_id']} from {channel_name}")
            logger.info(f"üìù Message text: {message_data.get('message', 'No text')[:100]}...")
            
            db = SessionLocal()
            
            # Find the source channel
            # Try with @ prefix first, then without
            channel = crud.get_source_channel_by_id(db, f"@{channel_name}")
            if not channel:
                channel = crud.get_source_channel_by_id(db, channel_name)
            if not channel:
                logger.warning(f"‚ùå Source channel {channel_name} (tried @{channel_name} and {channel_name}) not found in database")
                return
            
            logger.info(f"‚úÖ Found source channel: {channel.channel_name} (ID: {channel.id})")
            
            # Check if message already exists
            existing_post = crud.get_post_by_message_id(db, message_data['message_id'], channel.id)
            if existing_post:
                logger.info(f"‚ö†Ô∏è Message {message_data['message_id']} already exists as post {existing_post.id}")
                return  # Message already processed

            # Check if message has content (text or media)
            message_text = message_data.get('message', '')
            media_info = message_data.get('media')
            has_media = bool(media_info or message_data.get('media_type'))
            
            if not message_text.strip() and not has_media:
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Å–æ–æ–±—â–µ–Ω–∏–µ {message_data['message_id']} - –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –∏ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤")
                return

            # Prepare media data for storage
            original_media = None
            if media_info:
                # New format with media groups support
                original_media = media_info
            elif message_data.get('media_type'):
                # Legacy format - convert to new format
                original_media = {
                    'type': message_data.get('media_type'),
                    'path': message_data.get('media_path')
                }

            # Create new post from message
            post_data = {
                'source_channel_id': channel.id,
                'original_message_id': message_data['message_id'],
                'original_text': message_data['message'],
                'original_media': original_media
            }
            
            new_post = crud.create_post(db, PostCreate(**post_data))
            logger.info(f"üéâ Created new post {new_post.id} from message {message_data['message_id']} in {channel_name}")
            
            db.close()
            
        except Exception as e:
            logger.error(f"üí• Error handling new message from {channel_name}: {str(e)}")
            import traceback
            logger.error(f"üìã Traceback: {traceback.format_exc()}")
    
    async def fallback_monitoring(self):
        """Fallback periodic monitoring when continuous monitoring fails"""
        logger.info("üîÑ –ó–∞–ø—É—â–µ–Ω —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥")
        
        while self.running:
            try:
                logger.info("üîç Fallback –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥: –Ω–∞—á–∏–Ω–∞—é –Ω–æ–≤—ã–π —Ü–∏–∫–ª –ø—Ä–æ–≤–µ—Ä–∫–∏")
                db = SessionLocal()
                
                # Get active source channels
                channels = crud.get_source_channels(db, active_only=True)
                
                if not channels:
                    logger.info("üì≠ –ù–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –∫–∞–Ω–∞–ª–æ–≤ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤ fallback —Ä–µ–∂–∏–º–µ")
                    db.close()
                    await asyncio.sleep(15)
                    continue
                
                logger.info(f"üîÑ –ü—Ä–æ–≤–µ—Ä—è—é {len(channels)} –∫–∞–Ω–∞–ª–æ–≤ –≤ fallback —Ä–µ–∂–∏–º–µ...")
                
                checked_count = 0
                skipped_count = 0
                
                for channel in channels:
                    try:
                        logger.info(f"üîç Fallback: –ø—Ä–æ–≤–µ—Ä—è—é –∫–∞–Ω–∞–ª {channel.channel_name}")
                        
                        # Log channel check interval status
                        now = datetime.now(timezone.utc)
                        if channel.last_checked:
                            time_since_last_check = (now - channel.last_checked).total_seconds()
                            logger.info(f"üìä –ö–∞–Ω–∞–ª {channel.channel_name}: –ø–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ {time_since_last_check:.0f}—Å –Ω–∞–∑–∞–¥, –∏–Ω—Ç–µ—Ä–≤–∞–ª: {channel.check_interval}—Å")
                            
                            if time_since_last_check < channel.check_interval:
                                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é {channel.channel_name} - —Ä–∞–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å")
                                skipped_count += 1
                                continue
                        else:
                            logger.info(f"üìä –ö–∞–Ω–∞–ª {channel.channel_name}: –ø—Ä–æ–≤–µ—Ä—è–µ—Ç—Å—è –≤–ø–µ—Ä–≤—ã–µ")
                        
                        await self.check_channel_for_new_posts(db, channel)
                        checked_count += 1
                        
                    except Exception as e:
                        logger.error(f"Error checking channel {channel.channel_name}: {str(e)}")
                
                db.close()
                
                logger.info(f"üìä Fallback —Ü–∏–∫–ª –∑–∞–≤–µ—Ä—à–µ–Ω: –ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {checked_count} –∫–∞–Ω–∞–ª–æ–≤, –ø—Ä–æ–ø—É—â–µ–Ω–æ {skipped_count}")
                
                # Wait before next check - check every 15 seconds for better responsiveness
                logger.info("‚è≥ Fallback: –æ–∂–∏–¥–∞—é 15 —Å–µ–∫—É–Ω–¥ –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞–Ω–∞–ª–æ–≤...")
                await asyncio.sleep(15)
                
            except Exception as e:
                logger.error(f"Error in fallback monitoring: {str(e)}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
                await asyncio.sleep(15)
    
    async def check_channel_for_new_posts(self, db: Session, channel: SourceChannel):
        """Check a specific channel for new posts."""
        now = datetime.now(timezone.utc)
        
        # Check if it's time to check this channel (respecting interval)
        if channel.last_checked:
            time_since_last_check = (now - channel.last_checked).total_seconds()
            if time_since_last_check < channel.check_interval:
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é {channel.channel_name} - –ø—Ä–æ–≤–µ—Ä–µ–Ω {time_since_last_check:.0f}—Å –Ω–∞–∑–∞–¥ (–∏–Ω—Ç–µ—Ä–≤–∞–ª: {channel.check_interval}—Å)")
                return
        
        logger.info(f"üîç –ù–∞—á–∏–Ω–∞—é –∞–∫—Ç–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {channel.channel_name} ({channel.channel_id})")
        logger.info(f"üìÖ –í—Ä–µ–º—è –Ω–∞—á–∞–ª–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {now.strftime('%Y-%m-%d %H:%M:%S UTC')}")
        logger.info(f"üì® –ü–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π message ID: {channel.last_message_id or '–ù–µ—Ç'}")
        logger.info(f"‚è∞ –ü–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞: {channel.last_checked.strftime('%Y-%m-%d %H:%M:%S UTC') if channel.last_checked else '–ù–∏–∫–æ–≥–¥–∞'}")
        logger.info(f"‚öôÔ∏è –ò–Ω—Ç–µ—Ä–≤–∞–ª –ø—Ä–æ–≤–µ—Ä–∫–∏: {channel.check_interval} —Å–µ–∫—É–Ω–¥")
        
        try:
            logger.info(f"üì• –ü–æ–ª—É—á–∞—é —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –∫–∞–Ω–∞–ª–∞ (–ª–∏–º–∏—Ç: 10, offset_id: {channel.last_message_id or 0})...")
            logger.info(f"üîß –ü—Ä–æ–≤–µ—Ä—è—é telegram_service.client: {telegram_service.client is not None}")
            if telegram_service.client:
                try:
                    connected = telegram_service._is_client_connected()
                    logger.info(f"üîß Client connected: {connected}")
                except Exception as e:
                    logger.info(f"üîß Client connection check error: {e}")
            
            messages = await telegram_service.get_latest_messages(
                channel.channel_id,
                limit=10,
                offset_id=channel.last_message_id or 0
            )
            logger.info(f"üì• –ü–æ–ª—É—á–µ–Ω–æ {len(messages) if messages else 0} —Å–æ–æ–±—â–µ–Ω–∏–π –æ—Ç telegram_service")
            
            if not messages:
                logger.info(f"‚ùå –ù–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–∞–Ω–∞–ª–µ {channel.channel_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                crud.update_source_channel_last_checked(db, channel.id)
                return
            
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(messages)} —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –∫–∞–Ω–∞–ª–µ {channel.channel_name}")
            logger.info(f"üìä –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π...")
            
            new_posts_count = 0
            latest_message_id = channel.last_message_id or 0
            
            for i, message in enumerate(messages, 1):
                message_id = message.get('message_id', 0)
                message_text = message.get('text', '')
                message_date = message.get('date', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ')
                has_media = bool(message.get('media'))
                
                # Truncate text for logging
                display_text = message_text[:100] + '...' if len(message_text) > 100 else message_text
                
                logger.info(f"üìù [{i}/{len(messages)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å–æ–æ–±—â–µ–Ω–∏–µ ID: {message_id}")
                logger.info(f"üìÖ –î–∞—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è: {message_date}")
                logger.info(f"üìÑ –¢–µ–∫—Å—Ç: {display_text or '–ù–µ—Ç —Ç–µ–∫—Å—Ç–∞'}")
                logger.info(f"üñºÔ∏è –ú–µ–¥–∏–∞: {'–î–∞' if has_media else '–ù–µ—Ç'}")
                
                if message_id > (channel.last_message_id or 0):
                    # Check if message has content (text or media)
                    if not message_text.strip() and not has_media:
                        logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞—é —Å–æ–æ–±—â–µ–Ω–∏–µ {message_id} - –Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞ –∏ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤")
                        latest_message_id = max(latest_message_id, message_id)
                        continue
                    
                    # Check if we already have this post
                    existing_post = crud.get_post_by_source_message(db, channel.id, message_id)
                    if not existing_post:
                        # Create new post
                        post_data = {
                            'source_channel_id': channel.id,
                            'original_message_id': message_id,
                            'original_text': message_text,
                            'original_media': message.get('media', None)
                        }
                        
                        new_post = crud.create_post(db, PostCreate(**post_data))
                        new_posts_count += 1
                        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –ø–æ—Å—Ç ID: {new_post.id} –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è {message_id}")
                        logger.info(f"üìä –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {len(message_text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    else:
                        logger.info(f"‚ö†Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ {message_id} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∫–∞–∫ –ø–æ—Å—Ç {existing_post.id}")
                    
                    latest_message_id = max(latest_message_id, message_id)
                else:
                    logger.info(f"‚è≠Ô∏è –°–æ–æ–±—â–µ–Ω–∏–µ {message_id} –Ω–µ –Ω–æ–≤–µ–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ {channel.last_message_id or 0}")
                
                logger.info(f"{'‚îÄ' * 50}")  # Separator between messages
            
            # Update channel's last checked time and message ID
            crud.update_source_channel_last_checked(db, channel.id, latest_message_id)
            
            # Final summary
            logger.info(f"{'=' * 60}")
            logger.info(f"üèÅ –ó–∞–≤–µ—Ä—à–µ–Ω –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–Ω–∞–ª–∞: {channel.channel_name}")
            logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
            logger.info(f"   ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(messages)}")
            logger.info(f"   ‚Ä¢ –°–æ–∑–¥–∞–Ω–æ –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤: {new_posts_count}")
            logger.info(f"   ‚Ä¢ –ü–æ—Å–ª–µ–¥–Ω–∏–π message ID: {latest_message_id}")
            logger.info(f"   ‚Ä¢ –í—Ä–µ–º—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S UTC')}")
            
            if new_posts_count > 0:
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –Ω–∞–π–¥–µ–Ω–æ {new_posts_count} –Ω–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ {channel.channel_name}")
            else:
                logger.info(f"‚ÑπÔ∏è –ù–æ–≤—ã—Ö –ø–æ—Å—Ç–æ–≤ –≤ –∫–∞–Ω–∞–ª–µ {channel.channel_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            
            logger.info(f"{'=' * 60}")
            
        except Exception as e:
            logger.error(f"Error checking channel {channel.channel_name}: {str(e)}")
            # Still update last_checked to avoid getting stuck
            crud.update_source_channel_last_checked(db, channel.id)


async def main():
    """Main scrapper function with database-controlled lifecycle."""
    logger.info("üöÄ Scrapper main() function started - ENTRY POINT")
    logger.info("Scrapper process started")
    
    while True:
        try:
            # Check if scrapper should run
            logger.info("üîç Checking scrapper status in database...")
            db = SessionLocal()
            scrapper_status = crud.get_or_create_scrapper_status(db)
            logger.info(f"üìä Scrapper status: should_run={scrapper_status.should_run}, is_running={scrapper_status.is_running}")
            
            if scrapper_status.should_run:
                logger.info("Starting scrapper monitoring...")
                monitor = ChannelScrapper()
                
                try:
                    await monitor.start()
                except Exception as e:
                    logger.error(f"Scrapper error: {str(e)}")
                finally:
                    await monitor.stop()
                    logger.info("Scrapper monitoring stopped")
            else:
                logger.info("Scrapper is not set to run, waiting...")
                # Update status to show scrapper is not running
                crud.update_scrapper_status(db, is_running=False)
            
            db.close()
            
            # Wait before checking again
            await asyncio.sleep(10)
            
        except KeyboardInterrupt:
            logger.info("Received interrupt signal")
            break
        except Exception as e:
            logger.error(f"Unexpected error in main loop: {str(e)}")
            await asyncio.sleep(30)
    
    logger.info("Scrapper process stopped")


if __name__ == "__main__":
    print("üîß DEBUG: __main__ block reached - about to run main()")
    logger.info("üîß DEBUG: __main__ block reached - about to run main()")
    asyncio.run(main())